{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author: Antonio Moreno Martin**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import xgboost as xgb\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose, STL\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.arima_model import ARIMAResults\n",
    "from statsmodels.graphics.tsaplots import plot_predict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    '''\n",
    "    Crearemos features de time series basados en el index para estudiar luego su comportamiento\n",
    "    '''\n",
    "    \n",
    "    df = df.set_index('Fecha')\n",
    "    df['month'] = df.index.month\n",
    "    df['year'] = df.index.year\n",
    "    \n",
    "    return df\n",
    "\n",
    "def plot_prediction(df_total, df):\n",
    "    fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "\n",
    "    train =df_total.loc[:(len(df)-1)]\n",
    "    prediction = df_total.loc[(len(df)-1):]\n",
    "    prediction\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Line(name = \"Precio Real\", x = train.Fecha, y = train.Precio),\n",
    "        row=\n",
    "        1, col=1\n",
    "    )\n",
    "    fig.add_trace(        \n",
    "        go.Line(name = \"Precio Predicho\", x = prediction.Fecha, y = prediction.Precio),\n",
    "        row=\n",
    "        1, col=1\n",
    "    )\n",
    "    fig\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and gather downloaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer y gather data\n",
    "input = \"/Users/amm/Documents/Github/Data/Gasolina/source/Madrid_alcampo_gasolina_98_E5/\"\n",
    "files = glob.glob(input + '*.xls')\n",
    "\n",
    "df = pd.concat([pd.read_excel(file) for file in files], ignore_index=True)\n",
    "\n",
    "df['Fecha'] = pd.to_datetime(df['Fecha'])\n",
    "df.sort_values(by='Fecha', inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark> Define dates to train and test </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_train = '2023-04-01' # This is the last date of the train\n",
    "time_test = '2023-12-01' # This is the last date of the test\n",
    "time_to_predict = (datetime.strptime(time_train, '%Y-%m-%d')+ relativedelta(months=1)).strftime('%Y-%m-%d') # we add one month to start the prediction and convert back to string\n",
    "df_train = df[df['Fecha']<=time_train]\n",
    "df_test = df[df['Fecha']>time_train]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.line(df, x = 'Fecha', y = 'Precio', title = 'Gasolina 98 E5 Madrid 2020 - 2023')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_study = create_features(df)\n",
    "fig = px.box(df_study, x= \"month\", y=\"Precio\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Determinar si es un random walk o no\n",
    "# Vamos a determinar si es un random walk o no. Recordar que es un proceso donde hay mismas posibilidades tanto de ir hacia arriba o hacia abajo por un número aleatorio.\n",
    "# Step 1: Ver si existe una tendencia. En este caso, parece que puede haberlo ya que año a año ha ido incrementando.\n",
    "## 1.a Vamos a descomponerlo en tendencia, temporalidad y residuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_decomposition = STL(df['Precio'], period = 12).fit()\n",
    "\n",
    "fig = make_subplots(rows=4, cols=1, subplot_titles=(\"Observed\", \"Trend\", \"Seasonal\", \"Residuals\"))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Line(name = \"Valores reales\", x = df.Fecha, y = advanced_decomposition.observed),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Line(name = \"Tendencia\", x = df.Fecha, y = advanced_decomposition.trend),\n",
    "    row=2, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Line(name = \"Componente Estacional\", x = df.Fecha, y = advanced_decomposition.seasonal),\n",
    "    row=3, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Line(name = \"Residuos\", x = df.Fecha, y = advanced_decomposition.resid),\n",
    "    row=4, col=1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efectivamente, vemos una tendencia en la segunda gráfica. Vamos a salir de dudas con test ADF para ver el ACF(Autocorrelation function):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADF_result = adfuller(df.Precio)\n",
    "\n",
    "print(f'ADF Statistic: {ADF_result[0]}')\n",
    "print(f'p-value: {ADF_result[1]}')\n",
    "\n",
    "plot_acf(df.Precio, lags=12) # Vemos como hay una relación linela en las muestras y por tanto, es no estacionario. Dentro del confidence interval se considera que es como tener "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como el p valores mayor que 0.05, no podemos rechazar la null hyphotesis y por tanto es no estacionacionaria. Por ende, tennemos que volver a diferenciar por primera vez."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ACF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicar Dickey-Fuller test (ADF)  para saber si es temporal o no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "diff_gasolina = np.diff(df['Precio'], n = 1)\n",
    "print(f'ADF Statistic: {diff_gasolina[0]}')\n",
    "print(f'p-value: {diff_gasolina[1]}')\n",
    "plot_acf(diff_gasolina, lags = 12) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADF_result = adfuller(diff_gasolina)\n",
    "print(f'ADF Statistic: {ADF_result[0]}')\n",
    "print(f'p-value: {ADF_result[1]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**p valor menor que 0,05 y un ADF negativo no muy grande => por tanto, podemos rechazar la hipotesis nula y decir que es <mark>estacional</mark>**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos como tiene un comportamiento <mark> SINUSOIDAL pattern</mark> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Average (MA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>Uno de los motivos por los que hariamos MA, sería al dibujar el PACF (funcion parcial de autocorrelacion), donde tendríamos que ver un decay LINEAL. Recordamos que el MA era decay exponencial</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = df.copy()\n",
    "df_aux = df_aux.set_index('Fecha')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = df.copy()\n",
    "df_aux = df_aux.set_index('Fecha')\n",
    "\n",
    "train = df_aux.loc[df_aux.index <= time_train]\n",
    "test = df_aux.loc[df_aux.index > time_train]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_train = np.diff(train['Precio'], n = 1)\n",
    "indices_diff = train[1:].index.tolist()\n",
    "df_diff = pd.DataFrame({'diff_gasolina': diff_train})\n",
    "df_diff.index = indices_diff\n",
    "df_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = ARIMA(df_diff, order=(0,0,1))\n",
    "res = mod.fit()\n",
    "\n",
    "predict_ma = res.get_prediction(start = time_to_predict, end = time_test)\n",
    "prediction_ma = pd.DataFrame( columns=['predicted_MA'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>`len(df) - 1`</mark> se pone ya que cuando diferenciamos, el primer elemento se pierde, y por tanto, no podemos considerar el primer elemento que se encuentra en el lag 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame({'Fecha':predict_ma.predicted_mean.index, 'Precio':predict_ma.predicted_mean.values})\n",
    "df_ma = pd.concat([df_train, df_pred])\n",
    "df_ma = df_ma.reset_index(drop=True)\n",
    "\n",
    "df_ma['Precio'].loc[(len(df_train)-1):,] = df_ma['Precio'][(len(df_train)-1):].cumsum()\n",
    "df_ma\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT MA PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(df_ma, df_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the error with the predictions made"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El <mark>len(df)</mark> del modelo con el que hemos construido el MA es en este momento <mark>136</mark>, por ello, para calcular el error compararemos hasta ese número"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_ma = mean_squared_error(df_test['Precio'].loc[list(df_test.index)], df_ma['Precio'].loc[list(df_test.index)])\n",
    "mse_ma"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOREGRESSIVE MODEL (AR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>Al igual que para MA, es necesario dibujar su ACF, pero esta ve en lugar de decaer linealmente, deberíamos cerciorarnos de que decae exponencialmente<br>\n",
    "Por otra parte, a DIFERENCIA de MA, para conocer su grado MA(p), NO nos basta  con el ACF, en este caso debemos dibujar el PACF y ver donde deja de haber coeficientes no significativos</mark>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot PACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "plot_pacf(diff_gasolina, lags=20);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>Vemos, que a partir del lag 2, los coeficientes dejan de ser significativos, por ende, estamos frente a un AR(2)\n",
    "<br>\n",
    "Además, cabe destacar que tiene al igual que el ACF, un comportamiento sinusoidal, por ende, podemos aplicar un modelo ARMA</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = ARIMA(df_diff, order=(2,0,0)) # AR(2)\n",
    "res = mod.fit()\n",
    "\n",
    "predict_ar = res.get_prediction(start = time_to_predict, end = time_test)\n",
    "prediction_ar = pd.DataFrame( columns=['predicted_AR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- const = 0 y ar.L1 0.3 es igual a phi=0.3 en la ecuación matemática"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred =pd.DataFrame({'Fecha':predict_ar.predicted_mean.index, 'Precio':predict_ar.predicted_mean.values})\n",
    "df_ar = pd.concat([df_train, df_pred])\n",
    "df_ar = df_ar.reset_index(drop=True)\n",
    "\n",
    "df_ar['Precio'].loc[(len(df_train)-1):,] = df_ar['Precio'][(len(df_train)-1):].cumsum()\n",
    "df_ar\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT AR PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(df_ar, df_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_ar = mean_squared_error(df_test['Precio'].loc[list(df_test.index)], df_ar['Precio'].loc[list(df_test.index)])\n",
    "mse_ar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOREGRESSIVE MOVING AVERAGE (ARMA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>Para identificar si es un ARMA, tenemos que visualizar unos patrones sinusoidales o un patrón decaying TANTO en el ACF Y PACF por el cual no haya un claro lag donde se vuelva abruptamente no significante.</mark>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referencia:\n",
    "<br>\n",
    "<br>\n",
    "https://www.statsmodels.org/dev/examples/notebooks/generated/tsa_arma_0.html\n",
    "<br>\n",
    "<br>\n",
    "<mark> En funcion ARIMA(p, d, q) los parámetros que podemos rellenar para usar un ARMA son p y q, por ende, la d tiene que ser igual a cero cuando construyamos un ARMA model </mark>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestro caso, podemos ver como en ambos casos es sinusoidal, así que procederemos a aplicar un ARMA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIC to create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_opt_ARIMA(df_to_predict, grades, d):\n",
    "    '''\n",
    "    Función para fittear distintos ARMAS o ARIMAS con todas las combinaciones de grades que le indicaremos, eligiendo el modelo más óptimo (viendo su AIC)\n",
    "    Si queremos crear un ARMA, habrá que poner la 'd' a cero.\n",
    "    \n",
    "    df_to_predict: pandas dataframe\n",
    "        Es el df ya tratado previamente para poder aplicarle el modelo ARMA y predecir\n",
    "    \n",
    "    grades: int MAYOR QUE CERO\n",
    "        Creará una lista de 0 hasta grades\n",
    "        \n",
    "    '''\n",
    "    grades = list(range(0,grades + 1))\n",
    "    arma_mods = [ARIMA(df_to_predict, order=(p, d, q)).fit() for q in grades for p in grades]\n",
    "    aic = [arma.aic for arma in arma_mods]\n",
    "    ar = [list(arma.model_orders.values())[2]for arma in arma_mods] # Elegimos el valor 2, ya que en model_orders, es donde se encuentra el parametro p correspondiente al ar\n",
    "    ma = [list(arma.model_orders.values())[3]for arma in arma_mods]\n",
    "    \n",
    "    df_armas = pd.DataFrame(data = zip(ar, ma, aic), columns = [\"p\", \"q\", \"AIC\"])\n",
    "    df_armas = df_armas.sort_values(\"AIC\") # Ordenamos de MENOR a MAYOR, ya que el menor AIC  \n",
    "    return df_armas, arma_mods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>The lower the value for AIC, the better the fit of the model. The absolute value of the AIC value is not important. It can be positive or negative.</mark>\n",
    "<br>\n",
    "<br>\n",
    "**Reference**: https://www.statology.org/negative-aic/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_armas, arma_mods = create_opt_ARIMA(df_diff, 3, 0)\n",
    "df_armas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos el primer modelo al ser el que tiene menor AIC, por eso elegimos el [0]\n",
    "arma_model = arma_mods[df_armas.index.tolist()[0]]\n",
    "arma_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model's residuals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta este punto, viendo el AIC, nos damos cuenta que el mejor modelo es el ARMA(2,2). Ahora, debemos <mark>analizar los residuos</mark>, que no dejan de ser la diferencia entre el valor real\n",
    "<br> y el predicho para ver que dicha diferencia no es random. Eso se mira a través del <mark>QQplot</mark> y corriendo el <mark>Ljung-Boxtest</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = arma_model.resid\n",
    "residuals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QQ-PLOT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es una herramienta gráfica para verificar la hipotesis de que nuestro model's residuals tiene distribución normal.\n",
    "<br> Si el scatterplot se superpone a la lineal, diremos que tiene buen fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arma_model.plot_diagnostics(figsize=(10, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arma_predict = arma_model.get_prediction(start = time_to_predict, end = time_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame({'Fecha':arma_predict.predicted_mean.index, 'Precio':arma_predict.predicted_mean.values})\n",
    "df_arma = pd.concat([df_train, df_pred])\n",
    "df_arma = df_arma.reset_index(drop=True)\n",
    "\n",
    "df_arma['Precio'].loc[(len(df_train)-1):,] = df_arma['Precio'][(len(df_train)-1):].cumsum()\n",
    "df_arma\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT ARMA PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(df_arma, df_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_arma = mean_squared_error(df_test['Precio'].loc[list(df_test.index)], df_arma['Precio'].loc[list(df_test.index)])\n",
    "mse_arma"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOREGRESSIVE INTEGRATED MOVING AVERAGE MODEL (ARIMA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadiremos una componente a ARMA llamada el integration order denotado con la letra d. Con esta componente evitaremos tener en cuenta la no estacionalidad de las time series y evitar los pasos de transformación y diferenciación. Esta componente es simplemente la inversa de la diferenciación. <mark>Por ende, el orden de integración es igual al número de veces que una serie ha sido diferenciada hasta que se ha vuelto estacional. Por ejemplo, si diferenciamos una serie dos veces y se vuelve estacional d=2</mark>\n",
    "<br>\n",
    "<br>\n",
    "<mark>Resumiendo, el modelo ARIMA es como un modelo ARMA que puede ser aplicado en una serie no temporal sin necesidad de hacer todas las transformaciones que hacíamos, simplemente, ahora, tenemos que encontrar el orden de integración necesario para hacer la serie estacional </mark>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primer paso"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos que conocer el orden de diferenciación hasta que nuestra serie sea estacional. Por ello, iríamos aplicando el test de Dickey-Fuller a cada serie hasta que podamos rechazar la hipotesis nula y decir que es estacional (siempre que la serie original no fuese estacional).\n",
    "<br>\n",
    "<br>\n",
    "**Como dicho trabajo ya lo hemos hecho previamente, sabemos que el orden de diferenciación es en este caso 1 => d = 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_opt_ARIMA(df_to_predict, grades, d):\n",
    "    '''\n",
    "    Función para fittear distintos ARMAS o ARIMAS con todas las combinaciones de grades que le indicaremos, eligiendo el modelo más óptimo (viendo su AIC)\n",
    "    Si queremos crear un ARMA, habrá que poner la 'd' a cero.\n",
    "    \n",
    "    df_to_predict: pandas dataframe\n",
    "        Es el df ya tratado previamente para poder aplicarle el modelo ARMA y predecir\n",
    "    \n",
    "    grades: int MAYOR QUE CERO\n",
    "        Creará una lista de 0 hasta grades\n",
    "        \n",
    "    d: orden de diferenciacion, cuantas veces hay que diferenciar la serie para hacerla estacional\n",
    "        \n",
    "    '''\n",
    "    grades = list(range(0,grades + 1))\n",
    "    arma_mods = [ARIMA(df_to_predict, order=(p, d, q)).fit() for q in grades for p in grades]\n",
    "    aic = [arma.aic for arma in arma_mods]\n",
    "    ar = [list(arma.model_orders.values())[2]for arma in arma_mods] # Elegimos el valor 2, ya que en model_orders, es donde se encuentra el parametro p correspondiente al ar\n",
    "    ma = [list(arma.model_orders.values())[3]for arma in arma_mods]\n",
    "    \n",
    "    df_armas = pd.DataFrame(data = zip(ar, ma, aic), columns = [\"p\", \"q\", \"AIC\"])\n",
    "    df_armas = df_armas.sort_values(\"AIC\") # Ordenamos de MENOR a MAYOR, ya que el menor AIC  \n",
    "    return df_armas, arma_mods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arimas, arima_mods = create_opt_ARIMA(df_diff, 3, d = 1)\n",
    "df_arimas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos el primer modelo al ser el que tiene menor AIC, por eso elegimos el [0]\n",
    "arima_model = arima_mods[df_arimas.index.tolist()[0]]\n",
    "arima_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arma_model.plot_diagnostics(figsize=(10, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_predict = arima_model.get_prediction(start = time_to_predict, end = time_test)\n",
    "prediction_arima = pd.DataFrame( columns=['predicted_ARIMA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame({'Fecha':arima_predict.predicted_mean.index, 'Precio':arima_predict.predicted_mean.values})\n",
    "df_arima = pd.concat([df_train, df_pred])\n",
    "df_arima = df_arima.reset_index(drop=True)\n",
    "\n",
    "df_arima['Precio'].loc[(len(df_train)-1):,] = df_arima['Precio'][(len(df_train)-1):].cumsum()\n",
    "df_arima\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT ARIMA PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(df_arima, df_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_arima = mean_squared_error(df_test['Precio'].loc[list(df_test.index)], df_arima['Precio'].loc[list(df_test.index)])\n",
    "mse_arima"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEASONAL AUTOREGRESSIVE INTEGRATED MOVING AVERAGE MODEL (SARIMA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tendremos 3 parámetros nuevos frente al modelo ARIMA, y un parámetro m representando la frecuencia de la estacionalidad de la serie.\n",
    "En nuestro caso, no se ve gráficamente unos patrones de estacionalidad, por lo cual, es interesante volver al dibujo de decomposición que hicimos al principio. No se ve claramente un patrón, pero sí es cierto que los dos últimos años parece haber patrones. Por motivos prácticos, asumiremos una frecuencia de 12 representando los 12 meses de un año de periodicidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_opt_SARIMA(df_to_predict, grades, d, f):\n",
    "    '''\n",
    "    Función para fittear distintos SARIMA con todas las combinaciones de grades que le indicaremos, eligiendo el modelo más óptimo (viendo su AIC)\n",
    "    Si queremos crear un ARMA, habrá que poner la 'd' a cero.\n",
    "    \n",
    "    df_to_predict: pandas dataframe\n",
    "        Es el df ya tratado previamente para poder aplicarle el modelo ARMA y predecir\n",
    "    \n",
    "    grades: int MAYOR QUE CERO\n",
    "        Creará una lista de 0 hasta grades\n",
    "    \n",
    "    d: orden de diferenciacion, cuantas veces hay que diferenciar la serie para hacerla estacional\n",
    "    \n",
    "    f: frecuencia de la periodicidad\n",
    "        \n",
    "    '''\n",
    "    grades = list(range(0,grades + 1))\n",
    "    D = 0 \n",
    "    #https://www.statsmodels.org/dev/generated/statsmodels.tsa.statespace.sarimax.SARIMAXResults.html\n",
    "    arma_mods = [SARIMAX(df_to_predict, order=(p, d, q), seasonal_order = (P, D, Q, f)).fit(disp = False) for q in grades for p in grades for P in grades for Q in grades]\n",
    "    aic = [arma.aic for arma in arma_mods]\n",
    "    ar = [list(arma.model_orders.values())[2]for arma in arma_mods] # Elegimos el valor 2, ya que en model_orders, es donde se encuentra el parametro p correspondiente al ar\n",
    "    ma = [list(arma.model_orders.values())[3]for arma in arma_mods]\n",
    "    s_ar = [list(arma.model_orders.values())[4]for arma in arma_mods] \n",
    "    s_ma = [list(arma.model_orders.values())[5]for arma in arma_mods] \n",
    "    \n",
    "    df_armas = pd.DataFrame(data = zip(ar, ma, s_ar, s_ma, aic), columns = [\"p\",\"q\", \"P\",  \"Q\", \"AIC\"])\n",
    "    df_armas = df_armas.sort_values(\"AIC\") # Ordenamos de MENOR a MAYOR, ya que el menor AIC  \n",
    "    return df_armas, arma_mods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update = False # Si el modelo ya ha sido creado, hacemos load poniendo update = False, de lo contrarios, construimos el modelo de 0 poniendo update = True\n",
    "if update == True:\n",
    "    df_sarimas, sarima_mods = create_opt_SARIMA(df_diff, 4, d = 1, f = 12)\n",
    "    \n",
    "    # Seleccionamos el primer modelo al ser el que tiene menor AIC, por eso elegimos el [0]\n",
    "    sarima_model = sarima_mods[df_sarimas.index.tolist()[0]]\n",
    "    sarima_model.summary()\n",
    "    sarima_model.save('sarima_v2.pkl')\n",
    "else: \n",
    "    sarima_model = pickle.load(open('sarima_v1.pkl', 'rb'))\n",
    "    print(sarima_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_model.plot_diagnostics(figsize=(10, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_predict = sarima_model.get_prediction(start = time_to_predict, end = time_test)\n",
    "prediction_sarima = pd.DataFrame( columns=['predicted_SARIMA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.DataFrame({'Fecha':sarima_predict.predicted_mean.index, 'Precio':sarima_predict.predicted_mean.values})\n",
    "df_sarima = pd.concat([df_train, df_pred])\n",
    "df_sarima = df_sarima.reset_index(drop=True)\n",
    "\n",
    "df_sarima['Precio'].loc[(len(df_train)-1):,] = df_sarima['Precio'][(len(df_train)-1):].cumsum()\n",
    "df_sarima\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOT SARIMA PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(df_sarima, df_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_sarima = mean_squared_error(df_test['Precio'].loc[list(df_test.index)], df_sarima['Precio'].loc[list(df_test.index)])\n",
    "mse_sarima"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction(df_total, df):\n",
    "    fig = make_subplots(rows=1, cols=1)\n",
    "\n",
    "\n",
    "    train =df_total.loc[:(len(df)-1)]\n",
    "    prediction = df_total.loc[(len(df)-1):]\n",
    "    prediction\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Line(name = \"Precio Real\", x = train.Fecha, y = train.Precio),\n",
    "        row=\n",
    "        1, col=1\n",
    "    )\n",
    "    fig.add_trace(        \n",
    "        go.Line(name = \"Precio Predicho\", x = prediction.Fecha, y = prediction.Precio),\n",
    "        row=\n",
    "        1, col=1\n",
    "    )\n",
    "    fig\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mse = pd.DataFrame(columns = ['Model', 'MSE'])\n",
    "df_mse.loc[0]= ['MA', mse_ma]\n",
    "df_mse.loc[1]= ['AR', mse_ar]\n",
    "df_mse.loc[2]= ['ARMA', mse_arma]\n",
    "df_mse.loc[3]= ['ARIMA', mse_arima]\n",
    "df_mse.loc[4]= ['SARIMA', mse_sarima]\n",
    "df_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_mse = px.bar(df_mse, x='Model', y='MSE', title= 'Competeción MSE de los modelos construidos')\n",
    "fig_mse.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gasolina",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
